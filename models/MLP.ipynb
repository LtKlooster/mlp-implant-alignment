{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f8026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35165e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "n_epochs = 300\n",
    "learning_rate = 0.05\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de964d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom train validation test set split for reproducing purposes\n",
    "def train_val_test_split(X, y, training_size, val_every=10, test_every=10, test_offset=5, seed=seed):\n",
    "    \"\"\"\n",
    "    Custom data split with absolute training size and fixed patterns for validation/test set.\n",
    "\n",
    "    Args:\n",
    "        X, y: torch tensors of equal length\n",
    "        training_size (int): number of training samples to include\n",
    "        val_every (int): every nth sample goes to validation set\n",
    "        test_every (int): every nth sample goes to test set\n",
    "        test_offset (int): offset to start test selection (e.g. every 10th starting at index 5)\n",
    "        seed (int): random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test (torch tensors)\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(X)\n",
    "    indices = list(range(n))\n",
    "\n",
    "    # Validation set: every nth sample starting at index 0\n",
    "    val_indices = list(range(0, n, val_every))\n",
    "    # Test set: every nth sample starting at offset\n",
    "    test_indices = list(range(test_offset, n, test_every))\n",
    "\n",
    "    # Remaining samples are potential training candidates\n",
    "    remaining_indices = [i for i in indices if i not in val_indices + test_indices]\n",
    "\n",
    "    # Shuffle for randomness\n",
    "    random.seed(seed)\n",
    "    random.shuffle(remaining_indices)\n",
    "\n",
    "    # Cap training size to available data\n",
    "    training_size = min(training_size, len(remaining_indices))\n",
    "    train_indices = remaining_indices[:training_size]\n",
    "\n",
    "    # Helper to slice tensors by indices\n",
    "    def select(tensor, idxs):\n",
    "        return tensor[idxs]\n",
    "\n",
    "    X_train, y_train = select(X, train_indices), select(y, train_indices)\n",
    "    X_val, y_val = select(X, val_indices), select(y, val_indices)\n",
    "    X_test, y_test = select(X, test_indices), select(y, test_indices)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47096802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "df = pd.read_csv('../dataset/dummy_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603fad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and target columns\n",
    "X = df[[\"Fem_Fle(+)Ext(-)\", \"Fem_Var(+)Val(-)\", \"Fem_Int(+)Ext(-)\"]].values\n",
    "y = df[[\"f\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a5ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Split into train/val/test\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X, y, training_size=80)\n",
    "\n",
    "# Normalize y\n",
    "y_mean = y_train.mean()\n",
    "y_std = y_train.std()\n",
    "y_train = (y_train - y_mean) / y_std\n",
    "y_val = (y_val - y_mean) / y_std\n",
    "y_test = (y_test - y_mean) / y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5348e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensor datasets & dataloaders\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "val_ds = TensorDataset(X_val, y_val)\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(3, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, optimizer\n",
    "model = MLP()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d375f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            y_pred = model(X_batch)\n",
    "            val_loss += loss_fn(y_pred, y_batch).item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1:3d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1348ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluation\n",
    "model.eval()\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        y_pred = model(X_batch)\n",
    "        y_true_all.extend(y_batch.squeeze().tolist())\n",
    "        y_pred_all.extend(y_pred.squeeze().tolist())\n",
    "\n",
    "# Denormalize\n",
    "y_true_all = np.array(y_true_all)\n",
    "y_pred_all = np.array(y_pred_all)\n",
    "y_true_all = y_true_all * y_std.item() + y_mean.item()\n",
    "y_pred_all = y_pred_all * y_std.item() + y_mean.item()\n",
    "\n",
    "# Compute metrics\n",
    "mse = np.mean((y_true_all - y_pred_all) ** 2)\n",
    "mae = np.mean(np.abs(y_true_all - y_pred_all))\n",
    "\n",
    "print(f\" Test MSE: {mse:.6f}\")\n",
    "print(f\" Test MAE: {mae:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
